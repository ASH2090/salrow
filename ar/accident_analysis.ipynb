{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import firestore\n",
    "import os\n",
    "\n",
    "# --- Project Setup ---\n",
    "project_id = 'salrow-aa320'\n",
    "os.environ['GCLOUD_PROJECT'] = project_id\n",
    "\n",
    "# --- Firestore Connection ---\n",
    "try:\n",
    "    db = firestore.Client(project=project_id)\n",
    "    print(f\"Successfully connected to Firestore project: {project_id}\")\n",
    "    accidents_ref = db.collection('accidents')\n",
    "    print(\"Successfully created a reference to the 'accidents' collection.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to Firestore: {e}\")\n",
    "    print(\"Please ensure your service account key is correctly configured and has permissions.\")\n",
    "\n",
    "# --- Data Fetching ---\n",
    "print('\\nFetching all documents from the \\'accidents\\' collection...')\n",
    "# This will now fetch documents with all 27 columns\n",
    "docs = [doc.to_dict() for doc in accidents_ref.stream()]\n",
    "\n",
    "if not docs:\n",
    "    print('No documents found in the collection. Please ensure you have run the upload script.')\n",
    "else:\n",
    "    print(f\"Successfully fetched {len(docs)} documents.\")\n",
    "    df = pd.DataFrame(docs)\n",
    "\n",
    "    # --- Initial Data Analysis ---\n",
    "    print(\"\\n--- Data Analysis ---\")\n",
    "    print(\"DataFrame Info (with new columns):\")\n",
    "    # Displaying info will show us all the new columns and their data types\n",
    "    df.info()\n",
    "\n",
    "    print(\"\\nFirst 5 rows of the new DataFrame:\")\n",
    "    # Displaying the head will give a preview of the actual data\n",
    "    pd.set_option('display.max_columns', None) # Ensure all columns are displayed\n",
    "    print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: Feature Engineering - Calculate Accident Duration ---\n",
    "\n",
    "# Ensure the time columns are in the correct datetime format\n",
    "df['Start_Time'] = pd.to_datetime(df['Start_Time'])\n",
    "df['End_Time'] = pd.to_datetime(df['End_Time'])\n",
    "\n",
    "# Calculate the duration in minutes and create a new 'Duration' column\n",
    "# We get the total seconds of the time difference and convert it to minutes\n",
    "df['Duration'] = (df['End_Time'] - df['Start_Time']).dt.total_seconds() / 60\n",
    "\n",
    "# --- Handle Potential Data Issues ---\n",
    "# A small number of records might have a zero or negative duration due to data errors.\n",
    "# For our analysis, we will filter these out to avoid skewing the results.\n",
    "initial_count = len(df)\n",
    "df = df[df['Duration'] > 0].copy()\n",
    "print(f\"Removed {initial_count - len(df)} records with invalid (zero or negative) durations.\")\n",
    "print(f\"Now using {len(df)} valid records for analysis.\")\n",
    "\n",
    "# --- Step 3: Exploratory Analysis - The Impact of Junctions ---\n",
    "\n",
    "print(\"\\n--- Analysis: Average Accident Duration by Junction ---\")\n",
    "\n",
    "# Group the data by the 'Junction' column and calculate the average duration for each case\n",
    "junction_impact = df.groupby('Junction')['Duration'].mean()\n",
    "\n",
    "# Print the results in a clear, readable format\n",
    "print(f\"Average duration for accidents WITHOUT a junction: {junction_impact[False]:.2f} minutes\")\n",
    "print(f\"Average duration for accidents WITH a junction:    {junction_impact[True]:.2f} minutes\")\n",
    "\n",
    "# Show the first few rows with our new 'Duration' column\n",
    "print(\"\\n--- DataFrame Preview ---\")\n",
    "print(df[['ID', 'Start_Time', 'End_Time', 'Duration', 'Junction']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3 (Corrected): Comprehensive Analysis of All Road Conditions ---\n",
    "\n",
    "# List of all the boolean road condition columns we want to analyze\n",
    "# CORRECTED: 'Give_Way' is now included in the list.\n",
    "road_condition_columns = [\n",
    "    'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit', 'Railway',\n",
    "    'Roundabout', 'Station', 'Stop', 'Traffic_Calming', 'Traffic_Signal',\n",
    "    'Turning_Loop'\n",
    "]\n",
    "\n",
    "print(\"--- Analysis: Impact of All Road Conditions on Average Accident Duration ---\")\n",
    "\n",
    "# Loop through each road condition column and perform the same analysis as before\n",
    "for column in road_condition_columns:\n",
    "    print(f\"\\n----- Impact of: {column} -----\")\n",
    "\n",
    "    # Group by the current road condition and calculate the average duration\n",
    "    impact_analysis = df.groupby(column)['Duration'].mean()\n",
    "\n",
    "    # Use .get() to safely access the results, preventing errors if a\n",
    "    # category (e.g., True) doesn't exist for a particular feature.\n",
    "    avg_duration_false = impact_analysis.get(False, 0)\n",
    "    avg_duration_true = impact_analysis.get(True, 0)\n",
    "\n",
    "    # Print the results\n",
    "    if avg_duration_false > 0:\n",
    "        print(f\"Average duration WITHOUT this feature: {avg_duration_false:.2f} minutes\")\n",
    "    else:\n",
    "        print(\"No accidents recorded without this feature.\")\n",
    "\n",
    "    if avg_duration_true > 0:\n",
    "        print(f\"Average duration WITH this feature:    {avg_duration_true:.2f} minutes\")\n",
    "    else:\n",
    "        print(\"No accidents recorded with this feature.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# --- Step 4: Prepare Data for Modeling (No changes) ---\n",
    "\n",
    "feature_columns = [\n",
    "    'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit', 'Railway',\n",
    "    'Roundabout', 'Station', 'Stop', 'Traffic_Calming', 'Traffic_Signal',\n",
    "    'Turning_Loop'\n",
    "]\n",
    "target_column = 'Duration'\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df[target_column]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Step 5: Train and Evaluate Model (No changes) ---\n",
    "\n",
    "dt_model = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_pred = dt_model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"\\n--- Model Performance (using RMSE) ---\")\n",
    "print(f\"The model's prediction error (Root Mean Squared Error) is: {rmse:.2f} minutes.\")\n",
    "\n",
    "\n",
    "# --- CORRECTED: Interpret the Results with a Clean Index ---\n",
    "\n",
    "# Get the importance of each feature in making predictions\n",
    "feature_importances = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': dt_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False).reset_index(drop=True) # <-- This fixes the index\n",
    "\n",
    "print(\"\\n--- Most Important Predictors of Accident Duration (Corrected Sort) ---\")\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Corrected Analysis: Focusing on the Top 5 Most Important Predictors ---\n",
    "\n",
    "print(\"--- Analysis Part 1: Average Duration by Severity Level (Overall) ---\")\n",
    "\n",
    "# This part remains useful for context\n",
    "severity_impact = df.groupby('Severity')['Duration'].mean().sort_index()\n",
    "for severity_level, avg_duration in severity_impact.items():\n",
    "    print(f\"Severity Level {int(severity_level)}: Average accident duration is {avg_duration:.2f} minutes.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"--- Analysis Part 2: Detailed Breakdown for the TOP 5 PREDICTORS ---\")\n",
    "\n",
    "# CORRECTED: Define a list with only the top 5 most important features\n",
    "top_5_predictors = [\n",
    "    'Junction',\n",
    "    'Station',\n",
    "    'Crossing',\n",
    "    'Traffic_Signal',\n",
    "    'Stop'\n",
    "]\n",
    "\n",
    "# Loop through only the top predictors to analyze their impact within each severity level\n",
    "for column in top_5_predictors:\n",
    "    print(f\"\\n----- Impact of: {column} (broken down by Severity) -----\")\n",
    "\n",
    "    # Group by both Severity and the current road condition column\n",
    "    # Use .unstack() to pivot the data into a readable table format\n",
    "    detailed_impact = df.groupby(['Severity', column])['Duration'].mean().unstack()\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    detailed_impact.rename(columns={False: f'WITHOUT Feature', True: f'WITH Feature'}, inplace=True)\n",
    "\n",
    "    # Display the formatted results\n",
    "    print(detailed_impact.to_string(float_format=\"%.2f min\", na_rep=\"--\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# --- Part 2: Predictive Analysis with Severity ---\n",
    "print(\"Building the new, more powerful predictive model including 'Severity'.\")\n",
    "\n",
    "# --- Step 1: Prepare the Data for the New Model ---\n",
    "\n",
    "# Our features now include the top 5 road conditions AND the 'Severity' level.\n",
    "top_5_predictors = [\n",
    "    'Junction',\n",
    "    'Station',\n",
    "    'Crossing',\n",
    "    'Traffic_Signal',\n",
    "    'Stop'\n",
    "]\n",
    "features_with_severity = top_5_predictors + ['Severity']\n",
    "\n",
    "# Create a copy of the DataFrame to work with\n",
    "model_df = df[features_with_severity + ['Duration']].copy()\n",
    "\n",
    "# **Crucial Step: One-Hot Encode the 'Severity' column**\n",
    "# We use pd.get_dummies() to convert the single 'Severity' column (with values 1, 2, 3, 4)\n",
    "# into four new columns: 'Severity_1', 'Severity_2', etc. This treats each level as a distinct category.\n",
    "model_df = pd.get_dummies(model_df, columns=['Severity'], prefix='Severity')\n",
    "\n",
    "print(\"\\n--- Data Preparation ---\")\n",
    "print(\"The 'Severity' column has been converted into separate features:\")\n",
    "print(model_df.head())\n",
    "\n",
    "# --- Step 2: Define New Features (X) and Target (y) ---\n",
    "\n",
    "# The target remains the same\n",
    "target_column = 'Duration'\n",
    "\n",
    "# The features are all columns in our new DataFrame except for the target\n",
    "X_new = model_df.drop(target_column, axis=1)\n",
    "y_new = model_df[target_column]\n",
    "\n",
    "# Get the final list of feature columns for our report\n",
    "final_feature_columns = X_new.columns.tolist()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_new, y_new, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Step 3: Train and Evaluate the New Model ---\n",
    "\n",
    "# Initialize and train a new Decision Tree model\n",
    "dt_model_new = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "dt_model_new.fit(X_train_new, y_train_new)\n",
    "\n",
    "# Make predictions and evaluate the new model using RMSE\n",
    "y_pred_new = dt_model_new.predict(X_test_new)\n",
    "mse_new = mean_squared_error(y_test_new, y_pred_new)\n",
    "rmse_new = np.sqrt(mse_new)\n",
    "\n",
    "print(\"\\n--- New Model Performance ---\")\n",
    "print(f\"The new model's prediction error (RMSE) is: {rmse_new:.2f} minutes.\")\n",
    "print(\"This should be a significant improvement over the previous model which did not include 'Severity'.\")\n",
    "\n",
    "\n",
    "# --- Step 4: Find Most Important Predictors in the New Model ---\n",
    "\n",
    "# Get the importance of each feature in the new model\n",
    "feature_importances_new = pd.DataFrame({\n",
    "    'feature': final_feature_columns,\n",
    "    'importance': dt_model_new.feature_importances_\n",
    "}).sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n--- Most Important Predictors (Model with Severity) ---\")\n",
    "print(feature_importances_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- Visualize Model Performance: Actual vs. Predicted (with Zoom) ---\n",
    "\n",
    "# --- Step 1: Calculate the Zoom Limits ---\n",
    "# To zoom in, we'll find the 95th percentile of the actual and predicted durations.\n",
    "# This helps us ignore the extreme outliers that squash the plot.\n",
    "limit_value = max(np.percentile(y_test_new, 95), np.percentile(y_pred_new, 95))\n",
    "# We add a 10% buffer for a nice visual margin.\n",
    "zoom_limit = limit_value * 1.1\n",
    "\n",
    "# Calculate residuals for the second plot\n",
    "residuals = y_test_new - y_pred_new\n",
    "# We'll also zoom the residual plot's y-axis to see the error distribution more clearly.\n",
    "residual_zoom_limit = np.percentile(np.abs(residuals), 95) * 1.2 # 95th percentile of absolute error, with 20% buffer\n",
    "\n",
    "# --- Step 2: Create the Plots ---\n",
    "# Create a figure with two subplots (side-by-side)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# --- Plot 1: Actual vs. Predicted Duration ---\n",
    "ax1.scatter(y_test_new, y_pred_new, alpha=0.5, label='Model Predictions')\n",
    "ax1.plot([0, zoom_limit], [0, zoom_limit], 'r--', lw=2, label='Perfect Prediction') # Adjust line to new zoom\n",
    "ax1.set_xlabel('Actual Accident Duration (minutes)', fontsize=12)\n",
    "ax1.set_ylabel('Predicted Accident Duration (minutes)', fontsize=12)\n",
    "ax1.set_title('Decision Tree: Actual vs. Predicted (Zoomed In)', fontsize=16)\n",
    "ax1.grid(True)\n",
    "# ** NEW: Set the axis limits to zoom in **\n",
    "ax1.set_xlim(0, zoom_limit)\n",
    "ax1.set_ylim(0, zoom_limit)\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "# --- Plot 2: Residual Plot ---\n",
    "ax2.scatter(y_pred_new, residuals, alpha=0.5, edgecolors='g')\n",
    "ax2.axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "ax2.set_xlabel('Predicted Accident Duration (minutes)', fontsize=12)\n",
    "ax2.set_ylabel('Residual (Error) in minutes', fontsize=12)\n",
    "ax2.set_title('Residual Plot (Zoomed In)', fontsize=16)\n",
    "ax2.grid(True)\n",
    "# ** NEW: Set the axis limits to zoom in **\n",
    "ax2.set_xlim(0, zoom_limit)\n",
    "ax2.set_ylim(-residual_zoom_limit, residual_zoom_limit)\n",
    "\n",
    "\n",
    "# Display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Model Improvement: Using a Random Forest Regressor ---\n",
    "\n",
    "print(\"--- Training a more powerful Random Forest model... ---\")\n",
    "\n",
    "# Initialize the Random Forest model.\n",
    "# n_estimators=100 means we are building 100 decision trees.\n",
    "# random_state=42 ensures we get the same result every time.\n",
    "# n_jobs=-1 uses all available CPU cores to speed up training.\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Train the model on the same training data as before\n",
    "rf_model.fit(X_train_new, y_train_new)\n",
    "\n",
    "# Make predictions on the test data with our new model\n",
    "y_pred_rf = rf_model.predict(X_test_new)\n",
    "\n",
    "# --- Evaluate the New Random Forest Model ---\n",
    "mse_rf = mean_squared_error(y_test_new, y_pred_rf)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "\n",
    "print(\"\\n--- Model Performance Comparison ---\")\n",
    "# The previous RMSE was ~10.55 minutes, let's see how we did.\n",
    "print(f\"Previous Decision Tree RMSE: 10.55 minutes\")\n",
    "print(f\"New Random Forest RMSE:      {rmse_rf:.2f} minutes\")\n",
    "\n",
    "improvement = 10.55 - rmse_rf\n",
    "print(f\"This is an improvement of {improvement:.2f} minutes in average prediction error.\")\n",
    "\n",
    "# --- Visualize the Improved Predictions ---\n",
    "\n",
    "# Calculate zoom limits just like before\n",
    "limit_value_rf = max(np.percentile(y_test_new, 95), np.percentile(y_pred_rf, 95))\n",
    "zoom_limit_rf = limit_value_rf * 1.1\n",
    "\n",
    "residuals_rf = y_test_new - y_pred_rf\n",
    "residual_zoom_limit_rf = np.percentile(np.abs(residuals_rf), 95) * 1.2\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# Plot 1: Actual vs. Predicted (Random Forest)\n",
    "ax1.scatter(y_test_new, y_pred_rf, alpha=0.5, label='Random Forest Predictions')\n",
    "ax1.plot([0, zoom_limit_rf], [0, zoom_limit_rf], 'r--', lw=2, label='Perfect Prediction')\n",
    "ax1.set_xlabel('Actual Accident Duration (minutes)', fontsize=12)\n",
    "ax1.set_ylabel('Predicted Accident Duration (minutes)', fontsize=12)\n",
    "ax1.set_title('Random Forest: Actual vs. Predicted (Zoomed In)', fontsize=16)\n",
    "ax1.grid(True)\n",
    "ax1.set_xlim(0, zoom_limit_rf)\n",
    "ax1.set_ylim(0, zoom_limit_rf)\n",
    "ax1.legend()\n",
    "\n",
    "# Plot 2: Residual Plot (Random Forest)\n",
    "ax2.scatter(y_pred_rf, residuals_rf, alpha=0.5, edgecolors='g')\n",
    "ax2.axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "ax2.set_xlabel('Predicted Accident Duration (minutes)', fontsize=12)\n",
    "ax2.set_ylabel('Residual (Error) in minutes', fontsize=12)\n",
    "ax2.set_title('Residual Plot (Random Forest)', fontsize=16)\n",
    "ax2.grid(True)\n",
    "ax2.set_xlim(0, zoom_limit_rf)\n",
    "ax2.set_ylim(-residual_zoom_limit_rf, residual_zoom_limit_rf)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
